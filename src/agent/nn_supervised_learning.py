# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "numpy",
#     "pygame",
#     "torch",
#     "torchvision",
# ]
# ///

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pygame # For key constants
import os # For path joining
import json # Added for loading data

# INTEGRATION: Import constants from the common module
from src.common.constants import BOARD_WIDTH_TILES, BOARD_HEIGHT_TILES

# --- Constants and Configuration ---
pygame.init() # Initialize Pygame to use its key constants

# INTEGRATION: Use constants from src.common.constants
BOARD_WIDTH = BOARD_WIDTH_TILES
BOARD_HEIGHT = BOARD_HEIGHT_TILES

# INTEGRATION: Define model directory and ensure it exists
MODEL_DIR = "models"
MODEL_FILENAME = os.path.join(MODEL_DIR, "tetris_action_predictor.pth")


# Define standard Tetris shapes based on actual game blocks after mapping
# Game blocks: SquareBlock (O), TBlock (T), LineBlock (I), LBlock (L), ZBlock (Z)
# Missing from original ALL_SHAPES used in game: SBlock, JBlock
# MODIFIED: Align ALL_SHAPES with blocks available in the game via DataCollector
ALL_SHAPES = ['IBlock', 'OBlock', 'TBlock', 'LBlock', 'ZBlock']
SHAPE_TO_IDX = {shape: i for i, shape in enumerate(ALL_SHAPES)}
NUM_UNIQUE_SHAPES = len(ALL_SHAPES) # Used for one-hot encoding size

# Define the actions our NN will predict
POSSIBLE_ACTIONS = ["Left", "Right", "Rotate", "SoftDrop", "HardDrop"]
ACTION_TO_LABEL = {action: i for i, action in enumerate(POSSIBLE_ACTIONS)}
LABEL_TO_ACTION = {i: action for action, i in ACTION_TO_LABEL.items()}
NUM_ACTIONS = len(POSSIBLE_ACTIONS)

# Map Pygame keys (from data) to our defined action names
PYGAME_ACTION_MAP = {
    pygame.K_LEFT: "Left",
    pygame.K_RIGHT: "Right",
    pygame.K_UP: "Rotate",
    pygame.K_DOWN: "SoftDrop",
    pygame.K_SPACE: "HardDrop"
}

# Reverse mapping: Action names to Pygame keys (for NNAIPlayer output)
ACTION_NAME_TO_PYGAME_KEY = {v: k for k, v in PYGAME_ACTION_MAP.items()}


# --- Feature Engineering Functions (used by training and NNAIPlayer) ---
def get_board_features(board_state_np):
    """Calculates features from the board state."""
    if board_state_np.shape != (BOARD_HEIGHT, BOARD_WIDTH):
        raise ValueError(f"Expected board shape ({BOARD_HEIGHT},{BOARD_WIDTH}), got {board_state_np.shape}")

    column_heights = np.zeros(BOARD_WIDTH, dtype=float)
    for col in range(BOARD_WIDTH):
        for row in range(BOARD_HEIGHT):
            if board_state_np[row, col] == 1: # Assuming 1 represents a filled cell
                column_heights[col] = BOARD_HEIGHT - row
                break
    aggregate_height = np.sum(column_heights)
    num_holes = 0
    for col in range(BOARD_WIDTH):
        col_has_block = False
        for row in range(BOARD_HEIGHT):
            if board_state_np[row, col] == 1:
                col_has_block = True
            elif col_has_block and board_state_np[row, col] == 0: # Assuming 0 is empty
                num_holes += 1
    bumpiness = 0
    for i in range(BOARD_WIDTH - 1):
        bumpiness += abs(column_heights[i] - column_heights[i+1])
    completed_lines = 0
    for row in range(BOARD_HEIGHT):
        if np.all(board_state_np[row, :] == 1):
            completed_lines += 1

    norm_column_heights = column_heights / BOARD_HEIGHT
    norm_aggregate_height = aggregate_height / (BOARD_WIDTH * BOARD_HEIGHT)
    norm_num_holes = num_holes / (BOARD_WIDTH * BOARD_HEIGHT) # Max holes is roughly W*H
    norm_bumpiness = bumpiness / (BOARD_WIDTH * BOARD_HEIGHT) # Max bumpiness can be W*H in extreme cases
    norm_completed_lines = completed_lines / BOARD_HEIGHT

    return (norm_column_heights, norm_aggregate_height, norm_num_holes,
            norm_bumpiness, norm_completed_lines)

def featurize_training_data(data_point):
    """Converts a single raw data point (from training data list) into a flat feature vector and a label."""
    board_state_list = data_point['board_state']
    # Ensure board_state is float for feature calculations, game saves as int.
    board_state_np = np.array(board_state_list, dtype=float)


    (norm_col_heights, norm_agg_h, norm_holes,
     norm_bump, norm_lines) = get_board_features(board_state_np)

    # MODIFIED: Use NUM_UNIQUE_SHAPES for one-hot encoding size
    current_shape_one_hot = np.zeros(NUM_UNIQUE_SHAPES, dtype=float)
    current_shape_name = data_point['current_block_shape']
    # Map game-specific names to NN canonical names
    if current_shape_name == 'LineBlock': current_shape_name = 'IBlock'
    if current_shape_name == 'SquareBlock': current_shape_name = 'OBlock'
    # SBlock and JBlock are not generated by the current game code,
    # so no mapping needed for them from game specific names.

    shape_idx = SHAPE_TO_IDX.get(current_shape_name)
    if shape_idx is not None:
        current_shape_one_hot[shape_idx] = 1.0
    # else:
        # This case implies a shape from data is not in our ALL_SHAPES
        # print(f"Warning: Current shape '{current_shape_name}' not in SHAPE_TO_IDX during featurization.")


    rotation_norm = float(data_point['current_block_rotation']) / 360.0
    # Ensure current_block_pos is not None before accessing elements
    pos_x_norm = 0.0
    pos_y_norm = 0.0
    if data_point['current_block_pos']:
        pos_x_norm = float(data_point['current_block_pos'][0]) / BOARD_WIDTH
        pos_y_norm = float(data_point['current_block_pos'][1]) / BOARD_HEIGHT


    # MODIFIED: Use NUM_UNIQUE_SHAPES
    next_shape_one_hot = np.zeros(NUM_UNIQUE_SHAPES, dtype=float)
    next_shape_name = data_point['next_block_shape']
    if next_shape_name == 'LineBlock': next_shape_name = 'IBlock'
    if next_shape_name == 'SquareBlock': next_shape_name = 'OBlock'

    next_shape_idx = SHAPE_TO_IDX.get(next_shape_name)
    if next_shape_idx is not None:
        next_shape_one_hot[next_shape_idx] = 1.0
    # else:
        # print(f"Warning: Next shape '{next_shape_name}' not in SHAPE_TO_IDX during featurization.")


    features = np.concatenate([
        norm_col_heights, # Size: BOARD_WIDTH
        np.array([norm_agg_h, norm_holes, norm_bump, norm_lines]), # Size: 4
        current_shape_one_hot, # Size: NUM_UNIQUE_SHAPES
        np.array([rotation_norm, pos_x_norm, pos_y_norm]), # Size: 3
        next_shape_one_hot # Size: NUM_UNIQUE_SHAPES
    ]).astype(np.float32)

    action_key = data_point['action']
    action_name = PYGAME_ACTION_MAP.get(action_key)
    label = -1 # Default for unmappable/ignored actions
    if action_name and action_name in ACTION_TO_LABEL:
        label = ACTION_TO_LABEL[action_name]

    return features, label

# --- PyTorch Dataset ---
class TetrisDataset(Dataset):
    def __init__(self, data_points):
        self.features_list = []
        self.labels_list = []

        for dp in data_points:
            features, label = featurize_training_data(dp)
            if label != -1: # Only include data points with valid mapped actions
                self.features_list.append(features)
                self.labels_list.append(label)
            # else:
            #     print(f"Warning: Skipping training data point due to unmapped action: {dp.get('action')} or invalid shape.")

        if not self.features_list:
            # This can happen if all data points had unmapped actions or issues
            raise ValueError("No valid data points found for training after featurization and action mapping.")

    def __len__(self):
        return len(self.features_list)

    def __getitem__(self, idx):
        return torch.tensor(self.features_list[idx], dtype=torch.float), \
               torch.tensor(self.labels_list[idx], dtype=torch.long)

# --- Determine Input Feature Size ---
# Load a sample of data to determine the feature size dynamically
file_path = "data/tetris_training_data.json" # Standard path for collected data
INPUT_FEATURES_SIZE = 0
try:
    with open(file_path, 'r') as f:
        raw_data_points_for_size_calc = json.load(f)
    if not raw_data_points_for_size_calc:
        raise ValueError(f"Training data file '{file_path}' is empty.")

    # Keep only the first 2523 data points to match the original script's behavior for calculation if desired
    # raw_data_points_for_size_calc = raw_data_points_for_size_calc[:2523]

    # Featurize one data point to get the features size
    # Ensure there's at least one valid data point
    valid_sample_found = False
    for dp_sample in raw_data_points_for_size_calc:
        sample_features_for_size_calc, sample_label = featurize_training_data(dp_sample)
        if sample_label != -1: # Check if it's a valid point
            INPUT_FEATURES_SIZE = len(sample_features_for_size_calc)
            valid_sample_found = True
            # print(f"INPUT_FEATURES_SIZE determined: {INPUT_FEATURES_SIZE}")
            break
    if not valid_sample_found:
        raise ValueError("No valid data points in the sample data to determine feature size.")

except FileNotFoundError:
    print(f"Warning: Training data file '{file_path}' not found. INPUT_FEATURES_SIZE cannot be determined dynamically. Set manually or ensure data exists.")
    # Fallback or error: For robustness, you might set a default or raise an error.
    # Example: INPUT_FEATURES_SIZE = BOARD_WIDTH + 4 + NUM_UNIQUE_SHAPES + 3 + NUM_UNIQUE_SHAPES (as per concatenate order)
    # This would be: 10 + 4 + 5 + 3 + 5 = 27 (if ALL_SHAPES has 5 elements)
    INPUT_FEATURES_SIZE = BOARD_WIDTH + 4 + NUM_UNIQUE_SHAPES + 3 + NUM_UNIQUE_SHAPES
    print(f"Falling back to calculated INPUT_FEATURES_SIZE: {INPUT_FEATURES_SIZE}")
except ValueError as e:
    print(f"Error during feature size calculation: {e}")
    # Fallback if needed, or re-raise
    INPUT_FEATURES_SIZE = BOARD_WIDTH + 4 + NUM_UNIQUE_SHAPES + 3 + NUM_UNIQUE_SHAPES
    print(f"Falling back to calculated INPUT_FEATURES_SIZE: {INPUT_FEATURES_SIZE} due to error.")


# --- PyTorch Model ---
class TetrisActionPredictor(nn.Module):
    def __init__(self, input_size, num_actions_out): # Renamed num_actions to num_actions_out for clarity
        super(TetrisActionPredictor, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, num_actions_out) # Use num_actions_out
        )

    def forward(self, x):
        return self.network(x)

# --- Training and Evaluation ---
def train_model(model, dataloader, criterion, optimizer, num_epochs=10):
    print(f"\n--- Starting Training (Input features: {INPUT_FEATURES_SIZE}, Output actions: {NUM_ACTIONS}) ---")
    model.train()
    for epoch in range(num_epochs):
        epoch_loss = 0.0
        correct_predictions = 0
        total_predictions = 0
        for features, labels in dataloader:
            optimizer.zero_grad()
            outputs = model(features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
            _, predicted_labels = torch.max(outputs, 1)
            correct_predictions += (predicted_labels == labels).sum().item()
            total_predictions += labels.size(0)
        
        avg_epoch_loss = epoch_loss / len(dataloader) if len(dataloader) > 0 else 0
        accuracy = correct_predictions / total_predictions * 100 if total_predictions > 0 else 0
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}, Accuracy: {accuracy:.2f}%")
    print("--- Training Finished ---")

def evaluate_model(model, dataloader, criterion):
    print("\n--- Starting Evaluation ---")
    model.eval()
    total_loss = 0.0
    correct_predictions = 0
    total_predictions = 0
    if dataloader is None or len(dataloader) == 0 :
        print("Evaluation dataloader is empty or None. Skipping evaluation.")
        return 0.0, 0.0 # Return loss and accuracy

    with torch.no_grad():
        for features, labels in dataloader:
            outputs = model(features)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, predicted_labels = torch.max(outputs, 1)
            correct_predictions += (predicted_labels == labels).sum().item()
            total_predictions += labels.size(0)
    
    avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else 0
    accuracy = correct_predictions / total_predictions * 100 if total_predictions > 0 else 0
    print(f"Evaluation Results - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%")
    print("--- Evaluation Finished ---")
    return avg_loss, accuracy


# --- Placeholder Block Class (for NNAIPlayer integration and __main__ example) ---
# This is kept for the __main__ example. The NNAIPlayer will receive actual
# Block objects from src.game.block during live gameplay.
class PlaceholderBlock:
    def __init__(self, shape_name, rotation_degrees, x_pos, y_pos, points=None):
        self.shape_name = shape_name
        self.rotation = rotation_degrees
        self.x = x_pos
        self.y = y_pos
        self.points = points if points is not None else [] # Not strictly used by featurizer

# --- NNAIPlayer Class ---
class NNAIPlayer:
    def __init__(self, grid_width, grid_height, model_path=MODEL_FILENAME):
        # These are tile dimensions, matching BOARD_WIDTH and BOARD_HEIGHT from constants
        self.grid_width = grid_width
        self.grid_height = grid_height

        # Constants for featurization, using those defined at the top of this script
        self.board_width_const = BOARD_WIDTH
        self.board_height_const = BOARD_HEIGHT
        self.all_shapes_const = ALL_SHAPES # Uses the script's ALL_SHAPES
        self.shape_to_idx_const = SHAPE_TO_IDX # Uses the script's SHAPE_TO_IDX
        self.num_unique_shapes_const = NUM_UNIQUE_SHAPES

        self.label_to_action_const = LABEL_TO_ACTION
        self.action_name_to_pygame_key_const = ACTION_NAME_TO_PYGAME_KEY

        self.input_features_size = INPUT_FEATURES_SIZE # Dynamically determined
        self.num_actions = NUM_ACTIONS

        self.model = TetrisActionPredictor(self.input_features_size, self.num_actions)

        if os.path.exists(model_path):
            try:
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                self.model.load_state_dict(torch.load(model_path, map_location=device))
                self.model.to(device)
                self.model.eval()
                print(f"NNAIPlayer initialized. Loaded model from {model_path} to {device}.")
            except Exception as e:
                print(f"Error loading model: {e}. NNAIPlayer will use an untrained model.")
        else:
            print(f"Warning: Model file {model_path} not found. NNAIPlayer will use an untrained model.")
        
        print(f"NNAIPlayer initialized for a {self.grid_width}x{self.grid_height} grid. Features: {self.input_features_size}")


    def _featurize_live_game_state(self, game_board_state_np, current_block_obj, next_block_obj):
        """Converts live game state (board, current block obj, next block obj) into a feature vector."""
        # Ensure game_board_state_np is float for feature calculations
        game_board_state_np = game_board_state_np.astype(float)

        (norm_col_heights, norm_agg_h, norm_holes,
         norm_bump, norm_lines) = get_board_features(game_board_state_np)

        current_shape_one_hot = np.zeros(self.num_unique_shapes_const, dtype=float)
        current_shape_name = current_block_obj.shape_name # From actual game Block
        if current_shape_name == 'LineBlock': current_shape_name = 'IBlock'
        if current_shape_name == 'SquareBlock': current_shape_name = 'OBlock'
        
        shape_idx = self.shape_to_idx_const.get(current_shape_name)
        if shape_idx is not None:
            current_shape_one_hot[shape_idx] = 1.0
        # else:
        #     print(f"Warning (Live): Current shape '{current_shape_name}' not in SHAPE_TO_IDX.")


        rotation_norm = float(current_block_obj.rotation) / 360.0
        pos_x_norm = float(current_block_obj.x) / self.board_width_const
        pos_y_norm = float(current_block_obj.y) / self.board_height_const

        next_shape_one_hot = np.zeros(self.num_unique_shapes_const, dtype=float)
        next_shape_name = next_block_obj.shape_name # From actual game Block
        if next_shape_name == 'LineBlock': next_shape_name = 'IBlock'
        if next_shape_name == 'SquareBlock': next_shape_name = 'OBlock'
        
        next_shape_idx = self.shape_to_idx_const.get(next_shape_name)
        if next_shape_idx is not None:
            next_shape_one_hot[next_shape_idx] = 1.0
        # else:
        #     print(f"Warning (Live): Next shape '{next_shape_name}' not in SHAPE_TO_IDX.")

        features = np.concatenate([
            norm_col_heights,
            np.array([norm_agg_h, norm_holes, norm_bump, norm_lines]),
            current_shape_one_hot,
            np.array([rotation_norm, pos_x_norm, pos_y_norm]),
            next_shape_one_hot
        ]).astype(np.float32)

        # print(f"Live features len: {len(features)}") # Debug
        return features

    def get_next_move(self, game_board_state, current_block, next_block):
        """
        Determines the next move for the AI using the loaded neural network.
        """
        try:
            # Attribute checks for safety, assuming main.py passes valid game Block objects
            required_attrs = ['shape_name', 'rotation', 'x', 'y']
            for attr in required_attrs:
                if not hasattr(current_block, attr):
                    print(f"Error: current_block is missing '{attr}' attribute.")
                    return []
            if not hasattr(next_block, 'shape_name'):
                 print("Error: next_block object is missing 'shape_name' attribute.")
                 return []

            features_np = self._featurize_live_game_state(game_board_state, current_block, next_block)
            if len(features_np) != self.input_features_size:
                print(f"Error: Feature size mismatch. Expected {self.input_features_size}, got {len(features_np)}")
                return []
                
            features_tensor = torch.tensor(features_np, dtype=torch.float).unsqueeze(0)

            device = next(self.model.parameters()).device
            features_tensor = features_tensor.to(device)

            with torch.no_grad():
                prediction_scores = self.model(features_tensor)
                _, predicted_label_idx = torch.max(prediction_scores, 1)
            
            predicted_action_name = self.label_to_action_const.get(predicted_label_idx.item())

            if predicted_action_name:
                pygame_key = self.action_name_to_pygame_key_const.get(predicted_action_name)
                if pygame_key is not None:
                    return [pygame_key]
                else:
                    print(f"Warning: Predicted action name '{predicted_action_name}' has no Pygame key mapping.")
            else:
                print(f"Warning: Predicted label index {predicted_label_idx.item()} has no action name mapping.")

        except AttributeError as ae:
            print(f"AttributeError in NNAIPlayer get_next_move: {ae}. Check block object structure.")
            import traceback
            traceback.print_exc()
        except Exception as e:
            print(f"Error in NNAIPlayer get_next_move: {e}")
            import traceback
            traceback.print_exc()
        
        return [] # Default to no action on error or no mapping

    def update_game_state(self, game_board_state):
        # This method is called by DataCollector, NNAIPlayer could use it for RL in future.
        pass


# --- Main Execution (for training the model) ---
if __name__ == '__main__':
    print("--- Tetris AI: Feature Engineering & PyTorch NN ---")
    
    # INTEGRATION: Ensure model directory exists
    if not os.path.exists(MODEL_DIR):
        try:
            os.makedirs(MODEL_DIR)
            print(f"Created model directory: {MODEL_DIR}")
        except OSError as e:
            print(f"Error creating model directory {MODEL_DIR}: {e}")
            # Depending on severity, you might exit or try to proceed without saving
            # For now, we'll let it try to save and fail if dir creation failed

    raw_data_points = []
    try:
        # Path to the training data collected by data_collector.py
        training_data_path = "data/tetris_training_data.json"
        with open(training_data_path, 'r') as f:
            raw_data_points = json.load(f)
        print(f"Loaded {len(raw_data_points)} data points from {training_data_path}")

        # Optional: Limit data points for faster testing (as in original)
        # raw_data_points = raw_data_points[:2523]
        # print(f"Using {len(raw_data_points)} data points for training.")

    except FileNotFoundError:
        print(f"Error: Training data file not found at {training_data_path}. Cannot train model.")
        pygame.quit()
        exit()
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from {training_data_path}. Ensure it's valid.")
        pygame.quit()
        exit()
    except Exception as e:
        print(f"An error occurred loading data: {e}")
        pygame.quit()
        exit()


    if not raw_data_points:
        print("No raw data points loaded. Cannot proceed with dataset creation. Exiting.")
        pygame.quit()
        exit()

    try:
        dataset = TetrisDataset(raw_data_points)
        if len(dataset) == 0:
            print("No data to train on after filtering (e.g., all actions unmapped). Exiting.")
            pygame.quit()
            exit()

        # Splitting dataset
        train_size = int(0.8 * len(dataset))
        test_size = len(dataset) - train_size
        
        if train_size == 0 or test_size == 0 or len(dataset) < 2: # Need at least 1 for train and 1 for test for split
            print(f"Dataset too small for train/test split (Total: {len(dataset)}). Using all for training and testing.")
            train_dataset = dataset
            test_dataset = dataset # Or make test_dataset a subset if len(dataset) == 1
            if len(dataset) == 1: # Can't truly test, but can run through test_loader logic
                 print("Warning: Only 1 data point. Test set will be same as train set.")
        else:
            train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

        print(f"Dataset size: Total={len(dataset)}, Train={len(train_dataset)}, Test={len(test_dataset)}")

        # Handle cases where train_dataset or test_dataset might be empty after split logic for very small N
        train_loader = DataLoader(train_dataset, batch_size=min(32, len(train_dataset)), shuffle=True) if len(train_dataset) > 0 else None
        test_loader = DataLoader(test_dataset, batch_size=min(32, len(test_dataset)), shuffle=False) if len(test_dataset) > 0 else None

        # Initialize model using the dynamically determined or fallback INPUT_FEATURES_SIZE
        model = TetrisActionPredictor(INPUT_FEATURES_SIZE, NUM_ACTIONS)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)

        if train_loader:
            num_training_epochs = 50
            if len(train_dataset) < 20: # Heuristic for very small datasets
                num_training_epochs = max(5, len(train_dataset) * 2) # Adjust epochs for tiny data
                print(f"Adjusted training epochs to {num_training_epochs} due to small dataset size.")
            train_model(model, train_loader, criterion, optimizer, num_epochs=num_training_epochs)

            # Save the trained model
            torch.save(model.state_dict(), MODEL_FILENAME)
            print(f"Trained model saved to {MODEL_FILENAME}")
        else:
            print("Skipping training as train_loader is empty.")


        if test_loader:
            evaluate_model(model, test_loader, criterion)
        else:
            print("Skipping evaluation as test_loader is empty or None.")

        print("\n--- Example Prediction for a single data point (using featurize_training_data) ---")
        if raw_data_points: # Check if raw_data_points is not empty
            # Try to find a valid data point for example prediction
            user_sample_point_raw = None
            actual_label_idx = -1
            sample_idx = -1

            for i, dp_sample in enumerate(raw_data_points):
                # Need to check if this data point would be valid after featurization
                _, temp_label = featurize_training_data(dp_sample)
                if temp_label != -1:
                    user_sample_point_raw = dp_sample
                    sample_idx = i
                    break
            
            if user_sample_point_raw:
                features_for_sample, actual_label_idx = featurize_training_data(user_sample_point_raw)
                # actual_label_idx should be valid here because we checked above

                features_tensor = torch.tensor(features_for_sample, dtype=torch.float).unsqueeze(0)
                device = next(model.parameters()).device # Use model's current device
                features_tensor = features_tensor.to(device)

                model.eval() # Ensure model is in eval mode for prediction
                with torch.no_grad():
                    prediction_scores = model(features_tensor)
                    _, predicted_label_idx_tensor = torch.max(prediction_scores, 1)
                
                predicted_action_name = LABEL_TO_ACTION.get(predicted_label_idx_tensor.item(), "Unknown")
                actual_action_name = LABEL_TO_ACTION.get(actual_label_idx, "Unknown (Unmapped in original data)")

                print(f"Data Point Details (from raw_data_points index {sample_idx}):")
                print(f"  Current Shape: {user_sample_point_raw.get('current_block_shape')}, Rotation: {user_sample_point_raw.get('current_block_rotation')}")
                print(f"  Actual Action (from data key {user_sample_point_raw.get('action')}): {actual_action_name} (Label: {actual_label_idx})")
                print(f"  Predicted Action: {predicted_action_name} (Label: {predicted_label_idx_tensor.item()})")
            else:
                print("Could not find a valid sample data point for example prediction after featurization.")
        else:
            print("raw_data_points is empty, cannot run example prediction.")


        print("\n--- Example Usage of NNAIPlayer ---")
        if os.path.exists(MODEL_FILENAME): # Check if model was actually saved
            # Use BOARD_WIDTH and BOARD_HEIGHT which are tile dimensions
            ai_player = NNAIPlayer(grid_width=BOARD_WIDTH, grid_height=BOARD_HEIGHT, model_path=MODEL_FILENAME)

            # Create a dummy game state for testing NNAIPlayer
            dummy_board_state = np.zeros((BOARD_HEIGHT, BOARD_WIDTH), dtype=int)
            if BOARD_HEIGHT > 2 and BOARD_WIDTH > 6: # Basic check for bounds
                dummy_board_state[BOARD_HEIGHT-2, 3:7] = 1 # Represents some landed blocks
                dummy_board_state[BOARD_HEIGHT-1, :] = 1   # Represents a filled bottom line

            # Use the PlaceholderBlock for dummy objects as actual game.Block isn't imported here
            dummy_current_block = PlaceholderBlock(shape_name='TBlock', rotation_degrees=90, x_pos=4, y_pos=2)
            dummy_next_block = PlaceholderBlock(shape_name='LBlock', rotation_degrees=0, x_pos=0, y_pos=0) # x,y for next block don't matter much

            print("Querying NNAIPlayer for next move with dummy state:")
            predicted_actions_list = ai_player.get_next_move(dummy_board_state, dummy_current_block, dummy_next_block)

            if predicted_actions_list:
                predicted_pygame_key = predicted_actions_list[0]
                # pygame.key.name might not be initialized if pygame.display was not set
                action_key_name = "N/A"
                try:
                    action_key_name = pygame.key.name(predicted_pygame_key)
                except pygame.error:
                    pass # Pygame might not be fully display-initialized here
                print(f"NNAIPlayer predicted action (Pygame Key): {predicted_pygame_key} ({action_key_name})")
            else:
                print("NNAIPlayer did not predict a valid action for the dummy state.")
        else:
            print(f"Skipping NNAIPlayer example usage as model file {MODEL_FILENAME} was not found (likely due to no training or save error).")

    except ValueError as e:
        print(f"A ValueError occurred during the main execution: {e}")
        import traceback
        traceback.print_exc()
    except Exception as e:
        print(f"An unexpected error occurred in __main__: {e}")
        import traceback
        traceback.print_exc()

    pygame.quit()
    print("\n--- Script Finished ---")